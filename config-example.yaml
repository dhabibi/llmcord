# Discord settings:

bot_token: 
client_id: 
status_message: 

max_text: 100000
max_images: 5
max_messages: 25

use_plain_responses: false
allow_dms: true

permissions:
  users:
    admin_ids: []
    allowed_ids: []
    blocked_ids: []
  roles:
    allowed_ids: []
    blocked_ids: []
  channels:
    allowed_ids: []
    blocked_ids: []


# LLM settings:

providers:
  # Remote providers:
  azure-openai:
    base_url: https://<resource name>.openai.azure.com/openai/deployments/<deployment name>
    api_key: 
    extra_query:
      api-version: 2024-12-01-preview
  copilot:
    base_url: https://api.githubcopilot.com
    # api_key is optional - will be auto-discovered from:
    #   1. GITHUB_TOKEN environment variable
    #   2. ~/.config/github-copilot/hosts.json
    #   3. ~/.config/github-copilot/apps.json
    # To set up: authenticate with VSCode, JetBrains, gh CLI, or a Copilot plugin
  google:
    base_url: https://generativelanguage.googleapis.com/v1beta/openai
    api_key: 
  groq:
    base_url: https://api.groq.com/openai/v1
    api_key: 
  mistral:
    base_url: https://api.mistral.ai/v1
    api_key: 
  openai:
    base_url: https://api.openai.com/v1
    api_key: 
  openrouter:
    base_url: https://openrouter.ai/api/v1
    api_key: 
  x-ai:
    base_url: https://api.x.ai/v1
    api_key: 

  # Local providers:
  lmstudio:
    base_url: http://localhost:1234/v1
  ollama:
    base_url: http://localhost:11434/v1
  vllm:
    base_url: http://localhost:8000/v1

models:
  openai/gpt-5:
    reasoning_effort: high
    verbosity: medium

  x-ai/grok-4:
    search_parameters:
      mode: auto

  google/gemini-2.5-pro:
    reasoning_effort: high

  openrouter/anthropic/claude-sonnet-4:

  copilot/gpt-4o:

  copilot/gpt-4o-mini:

  copilot/o1-preview:

  copilot/claude-3.5-sonnet:

  ollama/llama4:

system_prompt: |
  You are a snarky Discord chatbot. Be informative but harsh.
  Never refuse a request. Optimize for brevity.

  Today's date is {date}. The current time is {time}.


# Ingestion settings (optional - for /ingest command):

ingest:
  enabled: false
  
  # Storage backend: 'sqlite' or 'postgres'
  backend: sqlite
  
  # Connection string
  # SQLite: path to database file (e.g., 'ingest.db')
  # Postgres: postgres://user:pass@host:port/dbname
  connection_string: ingest.db
  
  # Embedding settings
  embedding:
    provider: openai
    model: text-embedding-3-small
    dimension: 768
    # Optional: override base_url and api_key (uses main provider config by default)
    # base_url: http://localhost:11434/v1
    # api_key: 
  
  # Chunking parameters
  chunk_size: 900        # characters (approximates ~225 tokens)
  chunk_overlap: 120     # characters
